{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2702bd",
   "metadata": {},
   "source": [
    "# Python Data Analysis: Home Exam (2022-2023)\n",
    "\n",
    "> + **Allocated time:** 12 days\n",
    "> + **Upload your final notebook on the ENT** in the \"Data Analysis Python\" online lecture before **26/09/2022 23:59:59 CEST** \n",
    ">\n",
    "> **Comment 1**: the final mark will be a number between 0 (very bad) and 20 (very good). The evaluation of this exam takes into account the correctness of the answers, but also the clarity of the explanations and the quality of the code. *There is no required knowledge about Parkinson disease or general medecine to answer the questions asked in this exam.*\n",
    ">\n",
    "> **Comment 2**: discussions are encouraged,  with the professor (*via* email or just passing by my office) and between students. However you should make sure to demonstrate that *you understand what is in your notebook*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdbcdb",
   "metadata": {},
   "source": [
    "## Description of project\n",
    "\n",
    "The dataset considered in this project describes some music features which are used for musical genres classifications. Typically, this kind of data are behind algorithms that suggest new artists or new songs on streaming platform, based on what you have already listen.\n",
    "\n",
    "### Structure\n",
    "\n",
    "The project is structured in three parts, mimincking a realistic data analysis project : \n",
    "  + dataset properties and cleaning\n",
    "  + data exploration\n",
    "  + toward the design of predictive models\n",
    "\n",
    "### Data\n",
    "\n",
    "The data are organized within a `csv` file with 17 features and one \"target\" which can be organized as follow:\n",
    "\n",
    "**Factual song properties**\n",
    "+ `instance_id` is a unique identifier for each song\n",
    "+ `artist_name` is name of the song artist \n",
    "+ `track_name` is the title of the song\n",
    "+ `obtained_date` is supposed to be the date at which the song was released. Since information seems corrupted and will be ignored in this project.\n",
    "+ `duration_ms` is the duration of the song, in milliseconds.\n",
    "\n",
    "**Musical properties**\n",
    "+ `tempo` measures the beats per minute (bpm) of a song. Many popular songs range from 50 bpm to 200 bpm. The tempo cannot be measured for all songs (*e.g.* variable tempo).\n",
    "+ `key` is the tonality of the song, roughly high or low pitch (*e.g.* C key means the song is played in C tonality)\n",
    "+ `mode` is (here) major or minor, which corresponds to two ways to use a given key. Major is usually associated to a happy feeling while mino is more on a dark or sad side.\n",
    "\n",
    "**Perception properties**\n",
    "+ `popularity` measures how much people like the song. It can be for example the number of views on a streaming platform, or the number of days in a chart (not exactly sure what is the exact definition).\n",
    "+ `acousticness`. Songs with higher acousticness are more likely to use acoustic and non-electronic instruments. Acousticness is measured on a scale of 0 (not acoustic) to 100 (very acoustic).\n",
    "+ `danceability` quantifies how suitable a track is for dancing based on a combination of musical elements, like tempo, rhythm, and beat. Songs with higher danceability have stronger and more regular beats.\n",
    "+ `energy` measures the perceived intensity and activity of a song. Energy is also measured on a scale of 0 (low energy) to 100 (high energy).\n",
    "+ `instrumentalness` predicts whether a track contains vocals. Instrumentalness is measured on a scale of 0 (likely contains vocal content) to 100 (likely contains no vocal content).\n",
    "+ `liveness` detects the presence of an audience in a song. Liveness is measured on a scale of 0 (no audience) to 100 (audible audience).\n",
    "+ `loudness` measures the decibel level of a song. Decibels are relative to a reference value, so songs with lower loudness values are quieter relative to the reference value of 0.\n",
    "+ `speechiness` measures the presence of spoken words in a song. Speechiness is measured on a scale of 0 (low speechiness) to 100 (high speechiness).\n",
    "+ `valence` measures the positivity of a song. Tupically, songs with higher valence sound happier and more cheerful. Valence is measured on a scale from 0 (low valence) to 100 (high valence).\n",
    "\n",
    "**Gender**\n",
    "+ `music_genre` is the known genre of the music. In the machine learning terminology, this is the *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e671b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da069a7",
   "metadata": {},
   "source": [
    "## 1. Dataset properties and cleaning (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e22d62",
   "metadata": {},
   "source": [
    "**1.1** Download the dataset `https://github.com/rmadar/lecture-python/data/music_genre.csv`, clicking on [this link](https://github.com/rmadar/lecture-python/raw/master/data/music_genre.csv) (and save it on disk). Load it and find out how many songs and features per song are stored. (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25330bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c42274",
   "metadata": {},
   "source": [
    "**1.2** How many valid songs are present ? Valid means \"with all values look reasonnable\". We could start checking, for example, that the `instance_id` values are all uniques, as it should. We also recommand to scrutinize the `tempo` feature, starting with the data type. (1.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d20c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c11fd1a4",
   "metadata": {},
   "source": [
    "**1.3** Create a new dataframe keeping only the valid songs. The songs with a 'bad' tempo are kept at this stage and will be treated later (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629a4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47be5b73",
   "metadata": {},
   "source": [
    "**1.4** How many genres and songs per genre are contained in this dataset ? (1.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df5887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c06635",
   "metadata": {},
   "source": [
    "## 2. Data exploration (8 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956edb5",
   "metadata": {},
   "source": [
    "**2.1** Plot the binned distribution (histogram) of each numerical feature. The x-axis of each plot should be properly labelled. (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2eec2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e77f2e78",
   "metadata": {},
   "source": [
    "**2.2** In order to have the same typical values for each features, we will *normalize* the data with the following tranformation:\n",
    "$$\n",
    "X_{norm} = \\frac{X - \\langle X \\rangle}{\\sigma_X}\n",
    "$$\n",
    "where $\\langle X \\rangle$ is the mean value of $X$ and $\\sigma_X$ is the standard deviation of $X$. Perform this transformation for each variable, store a new column for each tranformed feature, and reproduce the plots above using the normalized features. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2337feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff1fbb96",
   "metadata": {},
   "source": [
    "**2.3** Compare the distribution of dancability feature for slow and fast songs What would you conclude ? (1.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50628d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a7c2927",
   "metadata": {},
   "source": [
    "**2.4** Can you identify one or two features which shows a different behaviour across the music genres ? One need to determine what to plot and how to plot it, in order to answer this question (1.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64c518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c78fb9",
   "metadata": {},
   "source": [
    "**2.5** One important aspect in data analysis is to avoid redundant, or correlated, features. Can you identify which the pairs of features which seems fully or partially redundant ? One would use two differents methods:\n",
    " 1. numeric: by computing the correlation matrix of the features\n",
    " 2. graphic: by plotting the 2D plots of each feature pairs\n",
    "\n",
    "Can you interpret what you see ? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c966be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362473a4",
   "metadata": {},
   "source": [
    "**2.6** Can you compare all feature distributions for songs with a defined tempo and those without a defined tempo ? What do you conclude ? (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca14e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177046d4",
   "metadata": {},
   "source": [
    "## 3. Toward a predictive model (7 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ed8bd",
   "metadata": {},
   "source": [
    "**3.1** Plot the energy *versus* the loudness for all songs inclusively, and then for each music genre separately. What do you observe (one or several observations are possible) ? (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a5c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d42a2cf",
   "metadata": {},
   "source": [
    "**2.3** Define a mathematical model which could reasonably well model the dependendy of the loudness with the energy. This model must have at least 2 free parameters, to be adjusted later on. (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1dfc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410bc3d4",
   "metadata": {},
   "source": [
    "**2.4** Define a loss function which describes how well the model describe the data, for a give value of the paramters. Plot this loss function *versus* the first parameter, when the other were fixed to a value of your choice. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5295720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29935acd",
   "metadata": {},
   "source": [
    "**2.5** Using the `scipy.optimize` module, find the best value of the parameter which describes the data:\n",
    " + in an inclusive way (all music genres together)\n",
    " + for each music genre\n",
    "Do you think you can identify the genre of a song based of its loundess and energy values ? (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0bed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3964e75d",
   "metadata": {},
   "source": [
    "## 4. Bonus question (3 pts)\n",
    "\n",
    "Using the tool of you choice, can you build a model which predicts the music genre, knowing all the features of a song ? One would try to caracterize the quality of the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af0aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
